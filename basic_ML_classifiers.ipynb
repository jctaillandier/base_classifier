{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    " \n",
    "# load the dataset\n",
    "def load_dataset(full_path):\n",
    "\t# load the dataset as a numpy array\n",
    "\tdataframe = read_csv(full_path, header=None, na_values='?')\n",
    "\t# drop rows with missing\n",
    "\tdataframe = dataframe.dropna()\n",
    "\t# split into inputs and outputs\n",
    "\tlast_ix = len(dataframe.columns) - 1\n",
    "\tX, y = dataframe.drop(last_ix, axis=1), dataframe[last_ix]\n",
    "\t# select categorical and numerical features\n",
    "\tcat_ix = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\tnum_ix = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\t# label encode the target variable to have the classes 0 and 1\n",
    "\ty = LabelEncoder().fit_transform(y)\n",
    "\treturn X.values, y, cat_ix, num_ix\n",
    "def evaluate_model(X, y, model):\n",
    "\t# define evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "import time\n",
    "start = time.time()\n",
    "# de\n",
    "grad_boos = GradientBoostingClassifier(n_estimators=100)\n",
    "names = 'GBM'\n",
    "\n",
    " \n",
    "# define the location of the dataset\n",
    "full_path = '../GeneralDatasets/Csv/0a_no1_e20.csv'\n",
    "# load the dataset\n",
    "X, y, cat_ix, num_ix = load_dataset(full_path)\n",
    "# define models\n",
    "results = list()\n",
    "# evaluate each model\n",
    "import tqdm\n",
    "# for i in tqdm.tqdm(range(len(models))):\n",
    "# define steps\n",
    "steps = [('c',OneHotEncoder(handle_unknown='ignore'),cat_ix), ('n',MinMaxScaler(),num_ix)]\n",
    "# one hot encode categorical, normalize numerical\n",
    "ct = ColumnTransformer(steps)\n",
    "# wrap the model i a pipeline\n",
    "pipeline = Pipeline(steps=[('t',ct),('m',grad_boos)])\n",
    "# evaluate the model and store results\n",
    "scores = evaluate_model(X, y, pipeline)\n",
    "print(f\"Time to run: {time.time()-start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with data sanitized with alpha = 9875: nan\n",
      "Accuracy with data sanitized with alpha = 80: nan\n",
      "Accuracy with data sanitized with alpha = 25: nan\n",
      "Accuracy with data sanitized with alpha = 0: nan\n"
     ]
    }
   ],
   "source": [
    "for i, score in enumerate(scores):\n",
    "    print(f\"Accuracy with data sanitized with alpha = {input_file[i].split('a')[0]}: {mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/jc/Desktop/udem_H20/thesis_research/reconstructor/data/disp_impact_remover_1.0.csv\n",
    "print(f\"Accuracy with data sanitized with disparate impact (a=1.0): {mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with data sanitized with alpha = 0.9875: 0.8460150242300162\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy with data sanitized with alpha = 0.9875: {mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.80: 0.8463982621103877\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy with data sanitized with alpha = 0.80: {mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.25: 0.8361822462673703\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy with data sanitized with alpha = 0.25: {mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy with data sanitized with alpha = 0: {mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from numpy import mean\n",
    "# from numpy import std\n",
    "# from pandas import read_csv\n",
    "# from matplotlib import pyplot\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn.ensemble import BaggingClassifier\n",
    " \n",
    "\n",
    "# # load the dataset\n",
    "# def load_dataset(full_path):\n",
    "# \t# load the dataset as a numpy array\n",
    "# \tdataframe = read_csv(full_path, header=None, na_values='?')\n",
    "# \t# drop rows with missing\n",
    "# \tdataframe = dataframe.dropna()\n",
    "# \t# split into inputs and outputs\n",
    "# \tlast_ix = len(dataframe.columns) - 1\n",
    "# \timport pdb;pdb.set_trace()    \n",
    "# \tX, y = dataframe.drop(9, axis=1), dataframe[9]\n",
    "# \t# select categorical and numerical features\n",
    "# \tcat_ix = X.select_dtypes(include=['object', 'bool']).columns\n",
    "# \tnum_ix = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "# \t# label encode the target variable to have the classes 0 and 1\n",
    "# \ty = LabelEncoder().fit_transform(y)\n",
    "# \treturn X.values, y, cat_ix, num_ix\n",
    " \n",
    "# # evaluate a model\n",
    "# def evaluate_model(X, y, model):\n",
    "# \t# define evaluation procedure\n",
    "# \tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# \t# evaluate model\n",
    "# \tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# \treturn scores\n",
    "\n",
    "# scores = []\n",
    "# input_file = ['9875a_no1_e20','80a_no1_e20', '25a_no1_e20', '0a_no1_e20']\n",
    "# for file in input_file:\n",
    "#     start = time.time()\n",
    "#     # de\n",
    "#     grad_boos = GradientBoostingClassifier(n_estimators=100)\n",
    "#     names = 'GBM'\n",
    "\n",
    "\n",
    "#     # define the location of the dataset\n",
    "#     full_path = f'../GeneralDatasets/Csv/{file}.csv'\n",
    "\n",
    "#     X, y, cat_ix, num_ix = load_dataset(full_path)\n",
    "#     # define models\n",
    "# #     import pdb;pdb.set_trace()\n",
    "\n",
    "#     steps = [('c',OneHotEncoder(handle_unknown='ignore'),cat_ix), ('n',MinMaxScaler(),num_ix)]\n",
    "#     # one hot encode categorical, normalize numerical\n",
    "#     ct = ColumnTransformer(steps)\n",
    "#     pipeline = Pipeline(steps=[('t',ct),('m',grad_boos)])\n",
    "#     score = evaluate_model(X, y, pipeline)\n",
    "#     scores.append(score)\n",
    "#     print(f\"Run completed for {file} in {(time.time()-start)/60} seconds\")\n",
    "# # summarize performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
